{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = pd.read_csv(\"taxi_pretreatment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depart_nom</th>\n",
       "      <th>depart_latitude</th>\n",
       "      <th>depart_longitude</th>\n",
       "      <th>depart_agglomeration</th>\n",
       "      <th>arrive_latitude</th>\n",
       "      <th>arrive_longitude</th>\n",
       "      <th>arrive_nom</th>\n",
       "      <th>arrive_agglomeration</th>\n",
       "      <th>distance</th>\n",
       "      <th>virages</th>\n",
       "      <th>embouteillage</th>\n",
       "      <th>prix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centre des handicapes</td>\n",
       "      <td>3.863966</td>\n",
       "      <td>11.490792</td>\n",
       "      <td>2</td>\n",
       "      <td>3.876103</td>\n",
       "      <td>11.497105</td>\n",
       "      <td>mokolo-marché</td>\n",
       "      <td>5</td>\n",
       "      <td>2.300</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Centre des handicapes</td>\n",
       "      <td>3.863967</td>\n",
       "      <td>11.490793</td>\n",
       "      <td>2</td>\n",
       "      <td>3.864167</td>\n",
       "      <td>11.496965</td>\n",
       "      <td>Total Melen</td>\n",
       "      <td>4</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centre des handicapes</td>\n",
       "      <td>3.863968</td>\n",
       "      <td>11.490794</td>\n",
       "      <td>2</td>\n",
       "      <td>3.862409</td>\n",
       "      <td>11.504112</td>\n",
       "      <td>Carefour EMIA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.614</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Centre des handicapes</td>\n",
       "      <td>3.863969</td>\n",
       "      <td>11.490795</td>\n",
       "      <td>2</td>\n",
       "      <td>3.892244</td>\n",
       "      <td>11.511425</td>\n",
       "      <td>Bastos(carrefour)</td>\n",
       "      <td>2</td>\n",
       "      <td>5.297</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centre des handicapes</td>\n",
       "      <td>3.863970</td>\n",
       "      <td>11.490796</td>\n",
       "      <td>2</td>\n",
       "      <td>3.876147</td>\n",
       "      <td>11.489672</td>\n",
       "      <td>Cité verte</td>\n",
       "      <td>2</td>\n",
       "      <td>2.300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              depart_nom  depart_latitude  depart_longitude  \\\n",
       "0  Centre des handicapes         3.863966         11.490792   \n",
       "1  Centre des handicapes         3.863967         11.490793   \n",
       "2  Centre des handicapes         3.863968         11.490794   \n",
       "3  Centre des handicapes         3.863969         11.490795   \n",
       "4  Centre des handicapes         3.863970         11.490796   \n",
       "\n",
       "   depart_agglomeration  arrive_latitude  arrive_longitude         arrive_nom  \\\n",
       "0                     2         3.876103         11.497105      mokolo-marché   \n",
       "1                     2         3.864167         11.496965        Total Melen   \n",
       "2                     2         3.862409         11.504112      Carefour EMIA   \n",
       "3                     2         3.892244         11.511425  Bastos(carrefour)   \n",
       "4                     2         3.876147         11.489672         Cité verte   \n",
       "\n",
       "   arrive_agglomeration  distance  virages  embouteillage  prix  \n",
       "0                     5     2.300        7              5   150  \n",
       "1                     4     7.500        3              3   100  \n",
       "2                     1     1.614        7              3   350  \n",
       "3                     2     5.297       14              3   350  \n",
       "4                     2     2.300       10              1   150  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2258, 3)\n"
     ]
    }
   ],
   "source": [
    "data = taxi_data.loc[:, ['distance', 'virages', 'prix']]\n",
    "data.dropna(inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance    float32:dense\n",
       "virages     float32:dense\n",
       "prix        float32:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.astype(np.float32) \n",
    "data.ftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1806, 2)\n",
      "(452, 2)\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"distance\", \"virages\", \"prix\"]]\n",
    "data_array = data.as_matrix() # to_records(index=False)\n",
    "\n",
    "X, y = data_array[:, [0,1]], data_array[:, 2]\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "m, n = X_train.shape\n",
    "u, v = X_test.shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train_bias = np.c_[X_train, np.float32(np.ones((m, 1)))]\n",
    "X_test_bias = np.c_[X_test, np.ones((u, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_data = tf.placeholder(shape=[None, n+1], dtype=np.float32, name=\"X\")\n",
    "y_data = tf.placeholder(shape=[None, 1], dtype=np.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X_data, theta, name=\"predictions\")\n",
    "error = y_pred - y_data\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.89)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 400\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train_bias[indices]\n",
    "    y_batch = y_train.reshape(-1, 1)[indices]\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 41117.8\n",
      "MSE = 26030.2\n",
      "MSE = 69841.3\n",
      "MSE = 81949.7\n",
      "MSE = 35193.5\n",
      "\n",
      "MSE = 18763.6\n",
      "MSE = 58248.3\n",
      "MSE = 56693.6\n",
      "MSE = 26402.9\n",
      "MSE = 16859.0\n",
      "\n",
      "MSE = 34114.6\n",
      "MSE = 44310.1\n",
      "MSE = 22823.1\n",
      "MSE = 14540.8\n",
      "MSE = 29001.7\n",
      "\n",
      "MSE = 32251.9\n",
      "MSE = 18333.8\n",
      "MSE = 10948.6\n",
      "MSE = 23564.4\n",
      "MSE = 26813.9\n",
      "\n",
      "MSE = 17292.9\n",
      "MSE = 16064.8\n",
      "MSE = 17370.9\n",
      "MSE = 21715.0\n",
      "MSE = 16291.6\n",
      "\n",
      "MSE = 15419.8\n",
      "MSE = 16431.4\n",
      "MSE = 20251.3\n",
      "MSE = 15048.7\n",
      "MSE = 15184.3\n",
      "\n",
      "MSE = 16648.3\n",
      "MSE = 16127.3\n",
      "MSE = 16076.1\n",
      "MSE = 13449.4\n",
      "MSE = 14687.1\n",
      "\n",
      "MSE = 18337.3\n",
      "MSE = 14372.4\n",
      "MSE = 15654.8\n",
      "MSE = 15566.4\n",
      "MSE = 15698.6\n",
      "\n",
      "MSE = 16626.5\n",
      "MSE = 14623.1\n",
      "MSE = 15938.5\n",
      "MSE = 14488.4\n",
      "MSE = 14641.4\n",
      "\n",
      "MSE = 11783.6\n",
      "MSE = 14735.7\n",
      "MSE = 15741.3\n",
      "MSE = 16905.7\n",
      "MSE = 14517.6\n",
      "\n",
      "MSE = 14828.5\n",
      "MSE = 13410.9\n",
      "MSE = 14935.2\n",
      "MSE = 11819.1\n",
      "MSE = 14329.1\n",
      "\n",
      "MSE = 15613.2\n",
      "MSE = 13050.8\n",
      "MSE = 14228.1\n",
      "MSE = 14070.8\n",
      "MSE = 12877.0\n",
      "\n",
      "MSE = 13501.0\n",
      "MSE = 14013.1\n",
      "MSE = 13272.3\n",
      "MSE = 13423.1\n",
      "MSE = 13294.0\n",
      "\n",
      "MSE = 13589.7\n",
      "MSE = 16259.9\n",
      "MSE = 13724.5\n",
      "MSE = 13097.3\n",
      "MSE = 14093.1\n",
      "\n",
      "MSE = 13664.5\n",
      "MSE = 14816.9\n",
      "MSE = 14970.3\n",
      "MSE = 14300.8\n",
      "MSE = 14302.2\n",
      "\n",
      "MSE = 16204.9\n",
      "MSE = 12524.6\n",
      "MSE = 15154.4\n",
      "MSE = 15831.5\n",
      "MSE = 12777.0\n",
      "\n",
      "MSE = 13320.0\n",
      "MSE = 12963.1\n",
      "MSE = 15759.2\n",
      "MSE = 11390.4\n",
      "MSE = 12675.5\n",
      "\n",
      "MSE = 13705.5\n",
      "MSE = 12234.1\n",
      "MSE = 12952.3\n",
      "MSE = 13530.3\n",
      "MSE = 13263.4\n",
      "\n",
      "MSE = 13884.9\n",
      "MSE = 11565.6\n",
      "MSE = 15369.0\n",
      "MSE = 12378.4\n",
      "MSE = 12835.9\n",
      "\n",
      "MSE = 12237.9\n",
      "MSE = 15000.7\n",
      "MSE = 15782.8\n",
      "MSE = 11823.7\n",
      "MSE = 14872.3\n",
      "\n",
      "MSE = 15171.5\n",
      "MSE = 14598.5\n",
      "MSE = 12282.5\n",
      "MSE = 14110.9\n",
      "MSE = 12415.6\n",
      "\n",
      "MSE = 16065.7\n",
      "MSE = 14575.6\n",
      "MSE = 11657.8\n",
      "MSE = 13417.1\n",
      "MSE = 13053.5\n",
      "\n",
      "MSE = 12725.4\n",
      "MSE = 14445.9\n",
      "MSE = 15089.6\n",
      "MSE = 13897.5\n",
      "MSE = 12365.4\n",
      "\n",
      "MSE = 12982.0\n",
      "MSE = 15073.1\n",
      "MSE = 13879.3\n",
      "MSE = 12759.8\n",
      "MSE = 14067.6\n",
      "\n",
      "MSE = 14532.0\n",
      "MSE = 15969.5\n",
      "MSE = 12392.4\n",
      "MSE = 13473.2\n",
      "MSE = 15130.4\n",
      "\n",
      "MSE = 13711.4\n",
      "MSE = 11989.5\n",
      "MSE = 12804.6\n",
      "MSE = 13803.4\n",
      "MSE = 12665.5\n",
      "\n",
      "MSE = 12962.6\n",
      "MSE = 13084.4\n",
      "MSE = 12447.0\n",
      "MSE = 15033.0\n",
      "MSE = 14800.8\n",
      "\n",
      "MSE = 12737.6\n",
      "MSE = 11354.5\n",
      "MSE = 12383.7\n",
      "MSE = 12573.4\n",
      "MSE = 15707.4\n",
      "\n",
      "MSE = 15235.7\n",
      "MSE = 12402.2\n",
      "MSE = 12145.0\n",
      "MSE = 12742.2\n",
      "MSE = 15485.2\n",
      "\n",
      "MSE = 11577.1\n",
      "MSE = 13475.4\n",
      "MSE = 13991.9\n",
      "MSE = 13398.1\n",
      "MSE = 13341.6\n",
      "\n",
      "MSE = 14609.1\n",
      "MSE = 13921.2\n",
      "MSE = 14882.0\n",
      "MSE = 13804.0\n",
      "MSE = 13243.9\n",
      "\n",
      "MSE = 14317.6\n",
      "MSE = 14596.8\n",
      "MSE = 14842.2\n",
      "MSE = 14138.0\n",
      "MSE = 14558.1\n",
      "\n",
      "MSE = 14636.1\n",
      "MSE = 13679.9\n",
      "MSE = 13953.2\n",
      "MSE = 11832.3\n",
      "MSE = 10428.9\n",
      "\n",
      "MSE = 12950.9\n",
      "MSE = 13758.2\n",
      "MSE = 13657.6\n",
      "MSE = 12418.5\n",
      "MSE = 13511.5\n",
      "\n",
      "MSE = 11795.1\n",
      "MSE = 13780.1\n",
      "MSE = 11181.2\n",
      "MSE = 18948.1\n",
      "MSE = 14257.6\n",
      "\n",
      "MSE = 15626.4\n",
      "MSE = 13349.1\n",
      "MSE = 12855.0\n",
      "MSE = 12520.2\n",
      "MSE = 12640.0\n",
      "\n",
      "MSE = 12647.3\n",
      "MSE = 14181.6\n",
      "MSE = 11192.8\n",
      "MSE = 12511.2\n",
      "MSE = 12713.5\n",
      "\n",
      "MSE = 12456.0\n",
      "MSE = 12135.4\n",
      "MSE = 15599.1\n",
      "MSE = 9562.12\n",
      "MSE = 12143.3\n",
      "\n",
      "MSE = 13325.3\n",
      "MSE = 12890.9\n",
      "MSE = 13522.0\n",
      "MSE = 14440.6\n",
      "MSE = 13386.3\n",
      "\n",
      "MSE = 11967.8\n",
      "MSE = 12181.1\n",
      "MSE = 14652.9\n",
      "MSE = 14404.8\n",
      "MSE = 11860.4\n",
      "\n",
      "MSE = 14189.9\n",
      "MSE = 12159.0\n",
      "MSE = 13479.8\n",
      "MSE = 14994.1\n",
      "MSE = 12170.7\n",
      "\n",
      "MSE = 14183.3\n",
      "MSE = 12290.9\n",
      "MSE = 13706.7\n",
      "MSE = 13113.1\n",
      "MSE = 14710.8\n",
      "\n",
      "MSE = 12195.6\n",
      "MSE = 12651.0\n",
      "MSE = 12982.1\n",
      "MSE = 12108.0\n",
      "MSE = 14335.0\n",
      "\n",
      "MSE = 13477.9\n",
      "MSE = 13058.9\n",
      "MSE = 13179.0\n",
      "MSE = 14630.6\n",
      "MSE = 12982.5\n",
      "\n",
      "MSE = 17208.8\n",
      "MSE = 10182.0\n",
      "MSE = 12344.3\n",
      "MSE = 12566.2\n",
      "MSE = 12517.3\n",
      "\n",
      "MSE = 11562.9\n",
      "MSE = 14546.3\n",
      "MSE = 12842.6\n",
      "MSE = 12705.0\n",
      "MSE = 14580.4\n",
      "\n",
      "MSE = 12078.2\n",
      "MSE = 10286.2\n",
      "MSE = 14475.6\n",
      "MSE = 11569.0\n",
      "MSE = 13563.9\n",
      "\n",
      "MSE = 12801.9\n",
      "MSE = 12743.6\n",
      "MSE = 12878.9\n",
      "MSE = 12676.8\n",
      "MSE = 13653.2\n",
      "\n",
      "MSE = 16747.5\n",
      "MSE = 10511.2\n",
      "MSE = 12040.5\n",
      "MSE = 13825.0\n",
      "MSE = 11107.4\n",
      "\n",
      "MSE = 12877.2\n",
      "MSE = 15127.7\n",
      "MSE = 13078.1\n",
      "MSE = 14432.0\n",
      "MSE = 11676.7\n",
      "\n",
      "MSE = 13332.1\n",
      "MSE = 14694.8\n",
      "MSE = 14945.2\n",
      "MSE = 13445.4\n",
      "MSE = 11380.4\n",
      "\n",
      "MSE = 9958.16\n",
      "MSE = 10846.9\n",
      "MSE = 9631.47\n",
      "MSE = 12765.5\n",
      "MSE = 11583.7\n",
      "\n",
      "MSE = 11458.5\n",
      "MSE = 11448.3\n",
      "MSE = 15598.5\n",
      "MSE = 13840.4\n",
      "MSE = 12565.2\n",
      "\n",
      "MSE = 10949.5\n",
      "MSE = 13220.4\n",
      "MSE = 12955.7\n",
      "MSE = 12285.2\n",
      "MSE = 11996.1\n",
      "\n",
      "MSE = 10096.8\n",
      "MSE = 11790.4\n",
      "MSE = 11348.0\n",
      "MSE = 14368.9\n",
      "MSE = 13454.0\n",
      "\n",
      "MSE = 13389.9\n",
      "MSE = 10530.9\n",
      "MSE = 14579.9\n",
      "MSE = 13336.9\n",
      "MSE = 11191.1\n",
      "\n",
      "MSE = 14100.2\n",
      "MSE = 11191.9\n",
      "MSE = 10155.4\n",
      "MSE = 14220.9\n",
      "MSE = 12251.8\n",
      "\n",
      "MSE = 13985.5\n",
      "MSE = 12757.7\n",
      "MSE = 11692.3\n",
      "MSE = 13680.6\n",
      "MSE = 13315.1\n",
      "\n",
      "MSE = 12529.1\n",
      "MSE = 13149.7\n",
      "MSE = 12159.8\n",
      "MSE = 12432.8\n",
      "MSE = 13569.8\n",
      "\n",
      "MSE = 15867.8\n",
      "MSE = 13610.9\n",
      "MSE = 12375.1\n",
      "MSE = 10075.6\n",
      "MSE = 12333.1\n",
      "\n",
      "MSE = 14160.1\n",
      "MSE = 12196.1\n",
      "MSE = 12569.5\n",
      "MSE = 13301.2\n",
      "MSE = 11620.4\n",
      "\n",
      "MSE = 12964.4\n",
      "MSE = 12374.6\n",
      "MSE = 13718.7\n",
      "MSE = 12764.0\n",
      "MSE = 12476.1\n",
      "\n",
      "MSE = 11277.6\n",
      "MSE = 12797.1\n",
      "MSE = 13062.9\n",
      "MSE = 12918.8\n",
      "MSE = 13330.0\n",
      "\n",
      "MSE = 12019.9\n",
      "MSE = 13555.0\n",
      "MSE = 13204.8\n",
      "MSE = 13616.3\n",
      "MSE = 12018.7\n",
      "\n",
      "MSE = 11805.0\n",
      "MSE = 13632.6\n",
      "MSE = 13698.3\n",
      "MSE = 11750.7\n",
      "MSE = 12942.0\n",
      "\n",
      "MSE = 11322.5\n",
      "MSE = 14397.4\n",
      "MSE = 12551.7\n",
      "MSE = 11673.4\n",
      "MSE = 11359.6\n",
      "\n",
      "MSE = 14317.6\n",
      "MSE = 14408.3\n",
      "MSE = 14443.6\n",
      "MSE = 13677.7\n",
      "MSE = 10500.2\n",
      "\n",
      "MSE = 13199.2\n",
      "MSE = 12331.9\n",
      "MSE = 12224.9\n",
      "MSE = 14453.1\n",
      "MSE = 14985.7\n",
      "\n",
      "MSE = 12602.9\n",
      "MSE = 10039.8\n",
      "MSE = 12666.4\n",
      "MSE = 14832.4\n",
      "MSE = 12048.3\n",
      "\n",
      "MSE = 12274.9\n",
      "MSE = 12344.3\n",
      "MSE = 13364.1\n",
      "MSE = 13004.0\n",
      "MSE = 12188.3\n",
      "\n",
      "MSE = 14081.0\n",
      "MSE = 10244.3\n",
      "MSE = 10762.0\n",
      "MSE = 12874.9\n",
      "MSE = 13113.2\n",
      "\n",
      "MSE = 13745.8\n",
      "MSE = 11163.1\n",
      "MSE = 13543.3\n",
      "MSE = 13861.1\n",
      "MSE = 13702.8\n",
      "\n",
      "MSE = 12455.9\n",
      "MSE = 11800.7\n",
      "MSE = 13392.9\n",
      "MSE = 10729.3\n",
      "MSE = 10749.1\n",
      "\n",
      "MSE = 11592.9\n",
      "MSE = 13255.4\n",
      "MSE = 12228.2\n",
      "MSE = 12947.6\n",
      "MSE = 11746.9\n",
      "\n",
      "MSE = 14575.9\n",
      "MSE = 11698.2\n",
      "MSE = 13032.4\n",
      "MSE = 13979.1\n",
      "MSE = 11413.3\n",
      "\n",
      "MSE = 13523.6\n",
      "MSE = 10473.8\n",
      "MSE = 14113.5\n",
      "MSE = 11572.7\n",
      "MSE = 14065.9\n",
      "\n",
      "MSE = 12064.6\n",
      "MSE = 10577.1\n",
      "MSE = 13079.8\n",
      "MSE = 12052.3\n",
      "MSE = 11595.2\n",
      "\n",
      "MSE = 11239.6\n",
      "MSE = 13131.7\n",
      "MSE = 12950.1\n",
      "MSE = 11351.7\n",
      "MSE = 14614.8\n",
      "\n",
      "MSE = 10751.2\n",
      "MSE = 14192.9\n",
      "MSE = 10718.1\n",
      "MSE = 11283.6\n",
      "MSE = 13259.8\n",
      "\n",
      "MSE = 13422.2\n",
      "MSE = 12834.3\n",
      "MSE = 10149.6\n",
      "MSE = 13030.7\n",
      "MSE = 9224.98\n",
      "\n",
      "MSE = 9593.88\n",
      "MSE = 11122.7\n",
      "MSE = 15534.8\n",
      "MSE = 10562.1\n",
      "MSE = 12659.0\n",
      "\n",
      "MSE = 9314.75\n",
      "MSE = 11206.1\n",
      "MSE = 13673.9\n",
      "MSE = 13136.3\n",
      "MSE = 13846.9\n",
      "\n",
      "MSE = 11626.4\n",
      "MSE = 11925.7\n",
      "MSE = 12290.5\n",
      "MSE = 9328.3\n",
      "MSE = 11405.6\n",
      "\n",
      "MSE = 13157.4\n",
      "MSE = 10981.4\n",
      "MSE = 12961.2\n",
      "MSE = 11428.7\n",
      "MSE = 11395.2\n",
      "\n",
      "MSE = 13584.5\n",
      "MSE = 12584.4\n",
      "MSE = 13693.7\n",
      "MSE = 13903.6\n",
      "MSE = 13169.2\n",
      "\n",
      "MSE = 12620.5\n",
      "MSE = 12010.5\n",
      "MSE = 12135.6\n",
      "MSE = 11878.0\n",
      "MSE = 10702.7\n",
      "\n",
      "MSE = 11201.0\n",
      "MSE = 13575.9\n",
      "MSE = 12942.5\n",
      "MSE = 12889.1\n",
      "MSE = 11644.7\n",
      "\n",
      "MSE = 12087.7\n",
      "MSE = 10923.4\n",
      "MSE = 10771.5\n",
      "MSE = 12441.1\n",
      "MSE = 14092.0\n",
      "\n",
      "MSE = 12921.6\n",
      "MSE = 11983.2\n",
      "MSE = 12342.4\n",
      "MSE = 11171.1\n",
      "MSE = 11542.9\n",
      "\n",
      "MSE = 13048.1\n",
      "MSE = 11005.1\n",
      "MSE = 13372.0\n",
      "MSE = 11432.4\n",
      "MSE = 13235.2\n",
      "\n",
      "MSE = 11207.4\n",
      "MSE = 12393.4\n",
      "MSE = 12241.3\n",
      "MSE = 15851.8\n",
      "MSE = 10515.1\n",
      "\n",
      "MSE = 12187.6\n",
      "MSE = 11624.5\n",
      "MSE = 11946.7\n",
      "MSE = 12182.3\n",
      "MSE = 10090.2\n",
      "\n",
      "MSE = 13639.4\n",
      "MSE = 12925.8\n",
      "MSE = 11326.3\n",
      "MSE = 12087.4\n",
      "MSE = 13529.4\n",
      "\n",
      "MSE = 13779.5\n",
      "MSE = 12586.2\n",
      "MSE = 12199.8\n",
      "MSE = 10927.3\n",
      "MSE = 9924.15\n",
      "\n",
      "MSE = 11195.5\n",
      "MSE = 11318.0\n",
      "MSE = 10343.1\n",
      "MSE = 10693.0\n",
      "MSE = 12518.7\n",
      "\n",
      "MSE = 11259.1\n",
      "MSE = 12969.3\n",
      "MSE = 11193.4\n",
      "MSE = 11727.0\n",
      "MSE = 12225.5\n",
      "\n",
      "MSE = 10451.0\n",
      "MSE = 11225.2\n",
      "MSE = 11566.4\n",
      "MSE = 14895.7\n",
      "MSE = 13503.1\n",
      "\n",
      "MSE = 14906.9\n",
      "MSE = 11704.3\n",
      "MSE = 12496.5\n",
      "MSE = 10004.3\n",
      "MSE = 13112.1\n",
      "\n",
      "MSE = 12811.2\n",
      "MSE = 11385.3\n",
      "MSE = 11142.5\n",
      "MSE = 14666.3\n",
      "MSE = 12735.1\n",
      "\n",
      "MSE = 12285.9\n",
      "MSE = 11408.1\n",
      "MSE = 11406.6\n",
      "MSE = 14879.5\n",
      "MSE = 8847.68\n",
      "\n",
      "Best theta:\n",
      "[[  23.62977028]\n",
      " [   2.13002682]\n",
      " [ 107.31280518]]\n"
     ]
    }
   ],
   "source": [
    "# mini-batch gradient descent\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    losses = pd.DataFrame([]);\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch, batch_size)\n",
    "            sess.run(training_op, feed_dict={X_data: X_batch, y_data: y_batch})\n",
    "            \n",
    "            print(\"MSE =\", mse.eval(feed_dict={X_data: X_batch, y_data: y_batch}))\n",
    "            loss = sess.run(mse, feed_dict={X_data: X_batch, y_data: y_batch})\n",
    "            losses = losses.append({ \"loss\": loss, \"step\": int(epoch*n_batches + batch) }, ignore_index=True)\n",
    "        print()\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEACAYAAABhzAtFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkxguMo7jOE5iuMg4juM4ifH/AcVlzpp0fMvXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19880bdeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the losses\n",
    "\n",
    "plt.plot(losses['step'], losses['loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.5\n",
    "learning_rate = 0.01\n",
    "\n",
    "def learning_rate_decay(learning_rate, epoch):\n",
    "    return learning_rate/(1 + decay_rate*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = tf.placeholder(np.float32, name=\"learning_rate\")\n",
    "\n",
    "learning_rate = 0.00275 # 0.0067625\n",
    "global_step = tf.Variable(0, name=\"globa_step\", trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate=learning_rate, \n",
    "    global_step=global_step, \n",
    "    decay_steps=1, \n",
    "    decay_rate=0.8, \n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) # MomentumOptimizer(learning_rate=learning_rate, momentum=0.89)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  44804.9 . Pred =  0\n",
      "MSE = 44804.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  25244.8 . Pred =  0\n",
      "MSE = 25244.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  20200.2 . Pred =  0\n",
      "MSE = 20200.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  18634.3 . Pred =  0\n",
      "MSE = 18634.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  17934.7 . Pred =  0\n",
      "MSE = 17934.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  17478.8 . Pred =  0\n",
      "MSE = 17478.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  17114.9 . Pred =  0\n",
      "MSE = 17114.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  16803.2 . Pred =  0\n",
      "MSE = 16803.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  16530.5 . Pred =  0\n",
      "MSE = 16530.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  16290.5 . Pred =  0\n",
      "MSE = 16290.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  16079.0 . Pred =  0\n",
      "MSE = 16079.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15892.3 . Pred =  0\n",
      "MSE = 15892.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15727.6 . Pred =  0\n",
      "MSE = 15727.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15582.1 . Pred =  0\n",
      "MSE = 15582.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15453.6 . Pred =  0\n",
      "MSE = 15453.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15340.1 . Pred =  0\n",
      "MSE = 15340.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15239.6 . Pred =  0\n",
      "MSE = 15239.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15150.8 . Pred =  0\n",
      "MSE = 15150.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15072.0 . Pred =  0\n",
      "MSE = 15072.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  15002.3 . Pred =  0\n",
      "MSE = 15002.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14940.4 . Pred =  0\n",
      "MSE = 14940.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14885.5 . Pred =  0\n",
      "MSE = 14885.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14836.6 . Pred =  0\n",
      "MSE = 14836.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14793.1 . Pred =  0\n",
      "MSE = 14793.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14754.4 . Pred =  0\n",
      "MSE = 14754.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14719.8 . Pred =  0\n",
      "MSE = 14719.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14688.8 . Pred =  0\n",
      "MSE = 14688.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14661.1 . Pred =  0\n",
      "MSE = 14661.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14636.2 . Pred =  0\n",
      "MSE = 14636.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14613.9 . Pred =  0\n",
      "MSE = 14613.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14593.7 . Pred =  0\n",
      "MSE = 14593.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14575.4 . Pred =  0\n",
      "MSE = 14575.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14558.9 . Pred =  0\n",
      "MSE = 14558.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14543.8 . Pred =  0\n",
      "MSE = 14543.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14530.1 . Pred =  0\n",
      "MSE = 14530.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14517.5 . Pred =  0\n",
      "MSE = 14517.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14506.0 . Pred =  0\n",
      "MSE = 14506.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14495.3 . Pred =  0\n",
      "MSE = 14495.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14485.5 . Pred =  0\n",
      "MSE = 14485.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14476.3 . Pred =  0\n",
      "MSE = 14476.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14467.8 . Pred =  0\n",
      "MSE = 14467.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14459.8 . Pred =  0\n",
      "MSE = 14459.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14452.3 . Pred =  0\n",
      "MSE = 14452.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14445.2 . Pred =  0\n",
      "MSE = 14445.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14438.5 . Pred =  0\n",
      "MSE = 14438.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14432.1 . Pred =  0\n",
      "MSE = 14432.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14426.0 . Pred =  0\n",
      "MSE = 14426.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14420.2 . Pred =  0\n",
      "MSE = 14420.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14414.5 . Pred =  0\n",
      "MSE = 14414.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14409.1 . Pred =  0\n",
      "MSE = 14409.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14403.9 . Pred =  0\n",
      "MSE = 14403.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14398.8 . Pred =  0\n",
      "MSE = 14398.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14393.8 . Pred =  0\n",
      "MSE = 14393.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14389.0 . Pred =  0\n",
      "MSE = 14389.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14384.3 . Pred =  0\n",
      "MSE = 14384.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14379.6 . Pred =  0\n",
      "MSE = 14379.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14375.1 . Pred =  0\n",
      "MSE = 14375.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14370.6 . Pred =  0\n",
      "MSE = 14370.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14366.2 . Pred =  0\n",
      "MSE = 14366.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14361.9 . Pred =  0\n",
      "MSE = 14361.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14357.6 . Pred =  0\n",
      "MSE = 14357.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14353.3 . Pred =  0\n",
      "MSE = 14353.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14349.1 . Pred =  0\n",
      "MSE = 14349.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14345.0 . Pred =  0\n",
      "MSE = 14345.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14340.8 . Pred =  0\n",
      "MSE = 14340.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14336.7 . Pred =  0\n",
      "MSE = 14336.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14332.7 . Pred =  0\n",
      "MSE = 14332.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14328.6 . Pred =  0\n",
      "MSE = 14328.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14324.6 . Pred =  0\n",
      "MSE = 14324.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14320.6 . Pred =  0\n",
      "MSE = 14320.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14316.6 . Pred =  0\n",
      "MSE = 14316.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14312.7 . Pred =  0\n",
      "MSE = 14312.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14308.7 . Pred =  0\n",
      "MSE = 14308.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14304.8 . Pred =  0\n",
      "MSE = 14304.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14300.8 . Pred =  0\n",
      "MSE = 14300.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14296.9 . Pred =  0\n",
      "MSE = 14296.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14293.0 . Pred =  0\n",
      "MSE = 14293.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14289.2 . Pred =  0\n",
      "MSE = 14289.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14285.3 . Pred =  0\n",
      "MSE = 14285.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14281.4 . Pred =  0\n",
      "MSE = 14281.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14277.6 . Pred =  0\n",
      "MSE = 14277.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14273.7 . Pred =  0\n",
      "MSE = 14273.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14269.9 . Pred =  0\n",
      "MSE = 14269.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14266.0 . Pred =  0\n",
      "MSE = 14266.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14262.2 . Pred =  0\n",
      "MSE = 14262.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14258.4 . Pred =  0\n",
      "MSE = 14258.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14254.6 . Pred =  0\n",
      "MSE = 14254.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14250.8 . Pred =  0\n",
      "MSE = 14250.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14247.0 . Pred =  0\n",
      "MSE = 14247.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14243.2 . Pred =  0\n",
      "MSE = 14243.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14239.4 . Pred =  0\n",
      "MSE = 14239.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14235.6 . Pred =  0\n",
      "MSE = 14235.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14231.9 . Pred =  0\n",
      "MSE = 14231.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14228.1 . Pred =  0\n",
      "MSE = 14228.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14224.4 . Pred =  0\n",
      "MSE = 14224.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14220.6 . Pred =  0\n",
      "MSE = 14220.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14216.9 . Pred =  0\n",
      "MSE = 14216.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14213.1 . Pred =  0\n",
      "MSE = 14213.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14209.4 . Pred =  0\n",
      "MSE = 14209.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14205.7 . Pred =  0\n",
      "MSE = 14205.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14201.9 . Pred =  0\n",
      "MSE = 14201.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14198.2 . Pred =  0\n",
      "MSE = 14198.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14194.5 . Pred =  0\n",
      "MSE = 14194.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14190.8 . Pred =  0\n",
      "MSE = 14190.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14187.1 . Pred =  0\n",
      "MSE = 14187.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14183.4 . Pred =  0\n",
      "MSE = 14183.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14179.7 . Pred =  0\n",
      "MSE = 14179.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14176.1 . Pred =  0\n",
      "MSE = 14176.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14172.4 . Pred =  0\n",
      "MSE = 14172.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14168.7 . Pred =  0\n",
      "MSE = 14168.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14165.0 . Pred =  0\n",
      "MSE = 14165.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14161.4 . Pred =  0\n",
      "MSE = 14161.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14157.7 . Pred =  0\n",
      "MSE = 14157.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14154.1 . Pred =  0\n",
      "MSE = 14154.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14150.4 . Pred =  0\n",
      "MSE = 14150.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14146.8 . Pred =  0\n",
      "MSE = 14146.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14143.2 . Pred =  0\n",
      "MSE = 14143.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14139.5 . Pred =  0\n",
      "MSE = 14139.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14135.9 . Pred =  0\n",
      "MSE = 14135.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14132.3 . Pred =  0\n",
      "MSE = 14132.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14128.7 . Pred =  0\n",
      "MSE = 14128.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14125.1 . Pred =  0\n",
      "MSE = 14125.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14121.5 . Pred =  0\n",
      "MSE = 14121.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14117.9 . Pred =  0\n",
      "MSE = 14117.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14114.3 . Pred =  0\n",
      "MSE = 14114.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14110.7 . Pred =  0\n",
      "MSE = 14110.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14107.1 . Pred =  0\n",
      "MSE = 14107.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14103.6 . Pred =  0\n",
      "MSE = 14103.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14100.0 . Pred =  0\n",
      "MSE = 14100.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14096.4 . Pred =  0\n",
      "MSE = 14096.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14092.9 . Pred =  0\n",
      "MSE = 14092.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14089.3 . Pred =  0\n",
      "MSE = 14089.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14085.8 . Pred =  0\n",
      "MSE = 14085.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14082.2 . Pred =  0\n",
      "MSE = 14082.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14078.7 . Pred =  0\n",
      "MSE = 14078.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14075.1 . Pred =  0\n",
      "MSE = 14075.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14071.6 . Pred =  0\n",
      "MSE = 14071.6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14068.1 . Pred =  0\n",
      "MSE = 14068.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14064.6 . Pred =  0\n",
      "MSE = 14064.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14061.1 . Pred =  0\n",
      "MSE = 14061.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14057.6 . Pred =  0\n",
      "MSE = 14057.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14054.1 . Pred =  0\n",
      "MSE = 14054.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14050.6 . Pred =  0\n",
      "MSE = 14050.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14047.1 . Pred =  0\n",
      "MSE = 14047.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14043.6 . Pred =  0\n",
      "MSE = 14043.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14040.1 . Pred =  0\n",
      "MSE = 14040.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14036.6 . Pred =  0\n",
      "MSE = 14036.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14033.2 . Pred =  0\n",
      "MSE = 14033.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14029.7 . Pred =  0\n",
      "MSE = 14029.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14026.2 . Pred =  0\n",
      "MSE = 14026.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14022.8 . Pred =  0\n",
      "MSE = 14022.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14019.3 . Pred =  0\n",
      "MSE = 14019.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14015.9 . Pred =  0\n",
      "MSE = 14015.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14012.4 . Pred =  0\n",
      "MSE = 14012.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14009.0 . Pred =  0\n",
      "MSE = 14009.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14005.6 . Pred =  0\n",
      "MSE = 14005.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  14002.1 . Pred =  0\n",
      "MSE = 14002.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13998.7 . Pred =  0\n",
      "MSE = 13998.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13995.3 . Pred =  0\n",
      "MSE = 13995.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13991.9 . Pred =  0\n",
      "MSE = 13991.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13988.5 . Pred =  0\n",
      "MSE = 13988.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13985.1 . Pred =  0\n",
      "MSE = 13985.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13981.7 . Pred =  0\n",
      "MSE = 13981.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13978.3 . Pred =  0\n",
      "MSE = 13978.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13974.9 . Pred =  0\n",
      "MSE = 13974.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13971.5 . Pred =  0\n",
      "MSE = 13971.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13968.2 . Pred =  0\n",
      "MSE = 13968.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13964.8 . Pred =  0\n",
      "MSE = 13964.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13961.4 . Pred =  0\n",
      "MSE = 13961.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13958.1 . Pred =  0\n",
      "MSE = 13958.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13954.7 . Pred =  0\n",
      "MSE = 13954.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13951.4 . Pred =  0\n",
      "MSE = 13951.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13948.0 . Pred =  0\n",
      "MSE = 13948.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13944.7 . Pred =  0\n",
      "MSE = 13944.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13941.3 . Pred =  0\n",
      "MSE = 13941.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13938.0 . Pred =  0\n",
      "MSE = 13938.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13934.7 . Pred =  0\n",
      "MSE = 13934.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13931.4 . Pred =  0\n",
      "MSE = 13931.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13928.1 . Pred =  0\n",
      "MSE = 13928.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13924.7 . Pred =  0\n",
      "MSE = 13924.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13921.4 . Pred =  0\n",
      "MSE = 13921.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13918.1 . Pred =  0\n",
      "MSE = 13918.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13914.8 . Pred =  0\n",
      "MSE = 13914.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13911.5 . Pred =  0\n",
      "MSE = 13911.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13908.3 . Pred =  0\n",
      "MSE = 13908.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13905.0 . Pred =  0\n",
      "MSE = 13905.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13901.7 . Pred =  0\n",
      "MSE = 13901.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13898.4 . Pred =  0\n",
      "MSE = 13898.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13895.2 . Pred =  0\n",
      "MSE = 13895.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13891.9 . Pred =  0\n",
      "MSE = 13891.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13888.6 . Pred =  0\n",
      "MSE = 13888.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13885.4 . Pred =  0\n",
      "MSE = 13885.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13882.1 . Pred =  0\n",
      "MSE = 13882.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13878.9 . Pred =  0\n",
      "MSE = 13878.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13875.7 . Pred =  0\n",
      "MSE = 13875.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13872.4 . Pred =  0\n",
      "MSE = 13872.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13869.2 . Pred =  0\n",
      "MSE = 13869.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13866.0 . Pred =  0\n",
      "MSE = 13866.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13862.7 . Pred =  0\n",
      "MSE = 13862.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13859.5 . Pred =  0\n",
      "MSE = 13859.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13856.3 . Pred =  0\n",
      "MSE = 13856.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13853.1 . Pred =  0\n",
      "MSE = 13853.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13849.9 . Pred =  0\n",
      "MSE = 13849.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13846.7 . Pred =  0\n",
      "MSE = 13846.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13843.5 . Pred =  0\n",
      "MSE = 13843.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13840.3 . Pred =  0\n",
      "MSE = 13840.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13837.1 . Pred =  0\n",
      "MSE = 13837.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13834.0 . Pred =  0\n",
      "MSE = 13834.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13830.8 . Pred =  0\n",
      "MSE = 13830.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13827.6 . Pred =  0\n",
      "MSE = 13827.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13824.5 . Pred =  0\n",
      "MSE = 13824.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13821.3 . Pred =  0\n",
      "MSE = 13821.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13818.1 . Pred =  0\n",
      "MSE = 13818.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13815.0 . Pred =  0\n",
      "MSE = 13815.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13811.9 . Pred =  0\n",
      "MSE = 13811.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13808.7 . Pred =  0\n",
      "MSE = 13808.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13805.6 . Pred =  0\n",
      "MSE = 13805.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13802.4 . Pred =  0\n",
      "MSE = 13802.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13799.3 . Pred =  0\n",
      "MSE = 13799.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13796.2 . Pred =  0\n",
      "MSE = 13796.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13793.1 . Pred =  0\n",
      "MSE = 13793.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13790.0 . Pred =  0\n",
      "MSE = 13790.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13786.9 . Pred =  0\n",
      "MSE = 13786.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13783.7 . Pred =  0\n",
      "MSE = 13783.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13780.6 . Pred =  0\n",
      "MSE = 13780.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13777.6 . Pred =  0\n",
      "MSE = 13777.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13774.5 . Pred =  0\n",
      "MSE = 13774.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13771.4 . Pred =  0\n",
      "MSE = 13771.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13768.3 . Pred =  0\n",
      "MSE = 13768.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13765.2 . Pred =  0\n",
      "MSE = 13765.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13762.1 . Pred =  0\n",
      "MSE = 13762.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13759.1 . Pred =  0\n",
      "MSE = 13759.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13756.0 . Pred =  0\n",
      "MSE = 13756.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13753.0 . Pred =  0\n",
      "MSE = 13753.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13749.9 . Pred =  0\n",
      "MSE = 13749.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13746.9 . Pred =  0\n",
      "MSE = 13746.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13743.8 . Pred =  0\n",
      "MSE = 13743.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13740.8 . Pred =  0\n",
      "MSE = 13740.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13737.7 . Pred =  0\n",
      "MSE = 13737.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13734.7 . Pred =  0\n",
      "MSE = 13734.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13731.7 . Pred =  0\n",
      "MSE = 13731.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13728.6 . Pred =  0\n",
      "MSE = 13728.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13725.6 . Pred =  0\n",
      "MSE = 13725.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13722.6 . Pred =  0\n",
      "MSE = 13722.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13719.6 . Pred =  0\n",
      "MSE = 13719.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13716.6 . Pred =  0\n",
      "MSE = 13716.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13713.6 . Pred =  0\n",
      "MSE = 13713.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13710.6 . Pred =  0\n",
      "MSE = 13710.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13707.6 . Pred =  0\n",
      "MSE = 13707.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13704.6 . Pred =  0\n",
      "MSE = 13704.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13701.6 . Pred =  0\n",
      "MSE = 13701.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13698.7 . Pred =  0\n",
      "MSE = 13698.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13695.7 . Pred =  0\n",
      "MSE = 13695.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13692.7 . Pred =  0\n",
      "MSE = 13692.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13689.7 . Pred =  0\n",
      "MSE = 13689.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13686.8 . Pred =  0\n",
      "MSE = 13686.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13683.8 . Pred =  0\n",
      "MSE = 13683.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13680.9 . Pred =  0\n",
      "MSE = 13680.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13677.9 . Pred =  0\n",
      "MSE = 13677.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13675.0 . Pred =  0\n",
      "MSE = 13675.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13672.0 . Pred =  0\n",
      "MSE = 13672.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13669.1 . Pred =  0\n",
      "MSE = 13669.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13666.2 . Pred =  0\n",
      "MSE = 13666.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13663.3 . Pred =  0\n",
      "MSE = 13663.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13660.3 . Pred =  0\n",
      "MSE = 13660.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13657.4 . Pred =  0\n",
      "MSE = 13657.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13654.5 . Pred =  0\n",
      "MSE = 13654.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13651.6 . Pred =  0\n",
      "MSE = 13651.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13648.7 . Pred =  0\n",
      "MSE = 13648.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13645.8 . Pred =  0\n",
      "MSE = 13645.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13642.9 . Pred =  0\n",
      "MSE = 13642.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13640.0 . Pred =  0\n",
      "MSE = 13640.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13637.1 . Pred =  0\n",
      "MSE = 13637.1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13634.2 . Pred =  0\n",
      "MSE = 13634.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13631.3 . Pred =  0\n",
      "MSE = 13631.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13628.5 . Pred =  0\n",
      "MSE = 13628.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13625.6 . Pred =  0\n",
      "MSE = 13625.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13622.7 . Pred =  0\n",
      "MSE = 13622.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13619.9 . Pred =  0\n",
      "MSE = 13619.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13617.0 . Pred =  0\n",
      "MSE = 13617.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13614.1 . Pred =  0\n",
      "MSE = 13614.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13611.3 . Pred =  0\n",
      "MSE = 13611.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13608.4 . Pred =  0\n",
      "MSE = 13608.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13605.6 . Pred =  0\n",
      "MSE = 13605.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13602.8 . Pred =  0\n",
      "MSE = 13602.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13599.9 . Pred =  0\n",
      "MSE = 13599.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13597.1 . Pred =  0\n",
      "MSE = 13597.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13594.3 . Pred =  0\n",
      "MSE = 13594.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13591.5 . Pred =  0\n",
      "MSE = 13591.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13588.6 . Pred =  0\n",
      "MSE = 13588.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13585.8 . Pred =  0\n",
      "MSE = 13585.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13583.0 . Pred =  0\n",
      "MSE = 13583.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13580.2 . Pred =  0\n",
      "MSE = 13580.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13577.4 . Pred =  0\n",
      "MSE = 13577.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13574.6 . Pred =  0\n",
      "MSE = 13574.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13571.8 . Pred =  0\n",
      "MSE = 13571.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13569.0 . Pred =  0\n",
      "MSE = 13569.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13566.2 . Pred =  0\n",
      "MSE = 13566.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13563.5 . Pred =  0\n",
      "MSE = 13563.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13560.7 . Pred =  0\n",
      "MSE = 13560.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13557.9 . Pred =  0\n",
      "MSE = 13557.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13555.2 . Pred =  0\n",
      "MSE = 13555.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13552.4 . Pred =  0\n",
      "MSE = 13552.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13549.6 . Pred =  0\n",
      "MSE = 13549.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13546.9 . Pred =  0\n",
      "MSE = 13546.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13544.1 . Pred =  0\n",
      "MSE = 13544.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13541.4 . Pred =  0\n",
      "MSE = 13541.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13538.6 . Pred =  0\n",
      "MSE = 13538.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13535.9 . Pred =  0\n",
      "MSE = 13535.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13533.2 . Pred =  0\n",
      "MSE = 13533.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13530.4 . Pred =  0\n",
      "MSE = 13530.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13527.7 . Pred =  0\n",
      "MSE = 13527.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13525.0 . Pred =  0\n",
      "MSE = 13525.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13522.3 . Pred =  0\n",
      "MSE = 13522.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13519.5 . Pred =  0\n",
      "MSE = 13519.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13516.8 . Pred =  0\n",
      "MSE = 13516.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13514.1 . Pred =  0\n",
      "MSE = 13514.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13511.4 . Pred =  0\n",
      "MSE = 13511.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13508.7 . Pred =  0\n",
      "MSE = 13508.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13506.0 . Pred =  0\n",
      "MSE = 13506.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13503.3 . Pred =  0\n",
      "MSE = 13503.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13500.6 . Pred =  0\n",
      "MSE = 13500.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13498.0 . Pred =  0\n",
      "MSE = 13498.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13495.3 . Pred =  0\n",
      "MSE = 13495.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13492.6 . Pred =  0\n",
      "MSE = 13492.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13489.9 . Pred =  0\n",
      "MSE = 13489.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13487.3 . Pred =  0\n",
      "MSE = 13487.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13484.6 . Pred =  0\n",
      "MSE = 13484.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13481.9 . Pred =  0\n",
      "MSE = 13481.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13479.3 . Pred =  0\n",
      "MSE = 13479.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13476.6 . Pred =  0\n",
      "MSE = 13476.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13474.0 . Pred =  0\n",
      "MSE = 13474.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13471.3 . Pred =  0\n",
      "MSE = 13471.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13468.7 . Pred =  0\n",
      "MSE = 13468.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13466.1 . Pred =  0\n",
      "MSE = 13466.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13463.4 . Pred =  0\n",
      "MSE = 13463.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13460.8 . Pred =  0\n",
      "MSE = 13460.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13458.2 . Pred =  0\n",
      "MSE = 13458.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13455.5 . Pred =  0\n",
      "MSE = 13455.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13452.9 . Pred =  0\n",
      "MSE = 13452.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13450.3 . Pred =  0\n",
      "MSE = 13450.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13447.7 . Pred =  0\n",
      "MSE = 13447.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13445.1 . Pred =  0\n",
      "MSE = 13445.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13442.5 . Pred =  0\n",
      "MSE = 13442.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13439.9 . Pred =  0\n",
      "MSE = 13439.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13437.3 . Pred =  0\n",
      "MSE = 13437.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13434.7 . Pred =  0\n",
      "MSE = 13434.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13432.1 . Pred =  0\n",
      "MSE = 13432.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13429.5 . Pred =  0\n",
      "MSE = 13429.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13427.0 . Pred =  0\n",
      "MSE = 13427.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13424.4 . Pred =  0\n",
      "MSE = 13424.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13421.8 . Pred =  0\n",
      "MSE = 13421.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13419.2 . Pred =  0\n",
      "MSE = 13419.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13416.7 . Pred =  0\n",
      "MSE = 13416.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13414.1 . Pred =  0\n",
      "MSE = 13414.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13411.6 . Pred =  0\n",
      "MSE = 13411.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13409.0 . Pred =  0\n",
      "MSE = 13409.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13406.5 . Pred =  0\n",
      "MSE = 13406.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13403.9 . Pred =  0\n",
      "MSE = 13403.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13401.4 . Pred =  0\n",
      "MSE = 13401.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13398.8 . Pred =  0\n",
      "MSE = 13398.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13396.3 . Pred =  0\n",
      "MSE = 13396.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13393.8 . Pred =  0\n",
      "MSE = 13393.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13391.2 . Pred =  0\n",
      "MSE = 13391.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13388.7 . Pred =  0\n",
      "MSE = 13388.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13386.2 . Pred =  0\n",
      "MSE = 13386.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13383.7 . Pred =  0\n",
      "MSE = 13383.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13381.2 . Pred =  0\n",
      "MSE = 13381.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13378.7 . Pred =  0\n",
      "MSE = 13378.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13376.2 . Pred =  0\n",
      "MSE = 13376.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13373.7 . Pred =  0\n",
      "MSE = 13373.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13371.2 . Pred =  0\n",
      "MSE = 13371.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13368.7 . Pred =  0\n",
      "MSE = 13368.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13366.2 . Pred =  0\n",
      "MSE = 13366.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13363.7 . Pred =  0\n",
      "MSE = 13363.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13361.2 . Pred =  0\n",
      "MSE = 13361.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13358.7 . Pred =  0\n",
      "MSE = 13358.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13356.2 . Pred =  0\n",
      "MSE = 13356.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13353.8 . Pred =  0\n",
      "MSE = 13353.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13351.3 . Pred =  0\n",
      "MSE = 13351.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13348.8 . Pred =  0\n",
      "MSE = 13348.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13346.4 . Pred =  0\n",
      "MSE = 13346.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13343.9 . Pred =  0\n",
      "MSE = 13343.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13341.5 . Pred =  0\n",
      "MSE = 13341.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13339.0 . Pred =  0\n",
      "MSE = 13339.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13336.6 . Pred =  0\n",
      "MSE = 13336.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13334.1 . Pred =  0\n",
      "MSE = 13334.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13331.7 . Pred =  0\n",
      "MSE = 13331.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13329.3 . Pred =  0\n",
      "MSE = 13329.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13326.8 . Pred =  0\n",
      "MSE = 13326.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13324.4 . Pred =  0\n",
      "MSE = 13324.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13322.0 . Pred =  0\n",
      "MSE = 13322.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13319.6 . Pred =  0\n",
      "MSE = 13319.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13317.1 . Pred =  0\n",
      "MSE = 13317.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13314.7 . Pred =  0\n",
      "MSE = 13314.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13312.3 . Pred =  0\n",
      "MSE = 13312.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13309.9 . Pred =  0\n",
      "MSE = 13309.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13307.5 . Pred =  0\n",
      "MSE = 13307.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13305.1 . Pred =  0\n",
      "MSE = 13305.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13302.7 . Pred =  0\n",
      "MSE = 13302.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13300.3 . Pred =  0\n",
      "MSE = 13300.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13297.9 . Pred =  0\n",
      "MSE = 13297.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13295.5 . Pred =  0\n",
      "MSE = 13295.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13293.1 . Pred =  0\n",
      "MSE = 13293.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13290.8 . Pred =  0\n",
      "MSE = 13290.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13288.4 . Pred =  0\n",
      "MSE = 13288.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13286.0 . Pred =  0\n",
      "MSE = 13286.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13283.7 . Pred =  0\n",
      "MSE = 13283.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13281.3 . Pred =  0\n",
      "MSE = 13281.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13278.9 . Pred =  0\n",
      "MSE = 13278.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13276.6 . Pred =  0\n",
      "MSE = 13276.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13274.2 . Pred =  0\n",
      "MSE = 13274.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13271.9 . Pred =  0\n",
      "MSE = 13271.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13269.5 . Pred =  0\n",
      "MSE = 13269.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13267.2 . Pred =  0\n",
      "MSE = 13267.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13264.8 . Pred =  0\n",
      "MSE = 13264.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13262.5 . Pred =  0\n",
      "MSE = 13262.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13260.2 . Pred =  0\n",
      "MSE = 13260.2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13257.8 . Pred =  0\n",
      "MSE = 13257.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13255.5 . Pred =  0\n",
      "MSE = 13255.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13253.2 . Pred =  0\n",
      "MSE = 13253.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13250.9 . Pred =  0\n",
      "MSE = 13250.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13248.5 . Pred =  0\n",
      "MSE = 13248.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13246.2 . Pred =  0\n",
      "MSE = 13246.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13243.9 . Pred =  0\n",
      "MSE = 13243.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13241.6 . Pred =  0\n",
      "MSE = 13241.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13239.3 . Pred =  0\n",
      "MSE = 13239.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13237.0 . Pred =  0\n",
      "MSE = 13237.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13234.7 . Pred =  0\n",
      "MSE = 13234.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13232.4 . Pred =  0\n",
      "MSE = 13232.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13230.1 . Pred =  0\n",
      "MSE = 13230.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13227.8 . Pred =  0\n",
      "MSE = 13227.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13225.5 . Pred =  0\n",
      "MSE = 13225.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13223.3 . Pred =  0\n",
      "MSE = 13223.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13221.0 . Pred =  0\n",
      "MSE = 13221.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13218.7 . Pred =  0\n",
      "MSE = 13218.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13216.5 . Pred =  0\n",
      "MSE = 13216.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13214.2 . Pred =  0\n",
      "MSE = 13214.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13211.9 . Pred =  0\n",
      "MSE = 13211.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13209.7 . Pred =  0\n",
      "MSE = 13209.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13207.4 . Pred =  0\n",
      "MSE = 13207.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13205.2 . Pred =  0\n",
      "MSE = 13205.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13202.9 . Pred =  0\n",
      "MSE = 13202.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13200.7 . Pred =  0\n",
      "MSE = 13200.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13198.4 . Pred =  0\n",
      "MSE = 13198.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13196.2 . Pred =  0\n",
      "MSE = 13196.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13193.9 . Pred =  0\n",
      "MSE = 13193.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13191.7 . Pred =  0\n",
      "MSE = 13191.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13189.5 . Pred =  0\n",
      "MSE = 13189.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13187.2 . Pred =  0\n",
      "MSE = 13187.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13185.0 . Pred =  0\n",
      "MSE = 13185.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13182.8 . Pred =  0\n",
      "MSE = 13182.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13180.6 . Pred =  0\n",
      "MSE = 13180.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13178.4 . Pred =  0\n",
      "MSE = 13178.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13176.2 . Pred =  0\n",
      "MSE = 13176.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13173.9 . Pred =  0\n",
      "MSE = 13173.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13171.7 . Pred =  0\n",
      "MSE = 13171.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13169.5 . Pred =  0\n",
      "MSE = 13169.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13167.3 . Pred =  0\n",
      "MSE = 13167.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13165.1 . Pred =  0\n",
      "MSE = 13165.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13163.0 . Pred =  0\n",
      "MSE = 13163.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13160.8 . Pred =  0\n",
      "MSE = 13160.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13158.6 . Pred =  0\n",
      "MSE = 13158.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13156.4 . Pred =  0\n",
      "MSE = 13156.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13154.2 . Pred =  0\n",
      "MSE = 13154.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13152.0 . Pred =  0\n",
      "MSE = 13152.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13149.9 . Pred =  0\n",
      "MSE = 13149.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13147.7 . Pred =  0\n",
      "MSE = 13147.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13145.5 . Pred =  0\n",
      "MSE = 13145.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13143.4 . Pred =  0\n",
      "MSE = 13143.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13141.2 . Pred =  0\n",
      "MSE = 13141.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13139.1 . Pred =  0\n",
      "MSE = 13139.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13136.9 . Pred =  0\n",
      "MSE = 13136.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13134.8 . Pred =  0\n",
      "MSE = 13134.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13132.6 . Pred =  0\n",
      "MSE = 13132.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13130.5 . Pred =  0\n",
      "MSE = 13130.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13128.3 . Pred =  0\n",
      "MSE = 13128.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13126.2 . Pred =  0\n",
      "MSE = 13126.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13124.1 . Pred =  0\n",
      "MSE = 13124.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13121.9 . Pred =  0\n",
      "MSE = 13121.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13119.8 . Pred =  0\n",
      "MSE = 13119.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13117.7 . Pred =  0\n",
      "MSE = 13117.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13115.6 . Pred =  0\n",
      "MSE = 13115.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13113.4 . Pred =  0\n",
      "MSE = 13113.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13111.3 . Pred =  0\n",
      "MSE = 13111.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13109.2 . Pred =  0\n",
      "MSE = 13109.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13107.1 . Pred =  0\n",
      "MSE = 13107.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13105.0 . Pred =  0\n",
      "MSE = 13105.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13102.9 . Pred =  0\n",
      "MSE = 13102.9\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13100.8 . Pred =  0\n",
      "MSE = 13100.8\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13098.7 . Pred =  0\n",
      "MSE = 13098.7\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13096.6 . Pred =  0\n",
      "MSE = 13096.6\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13094.5 . Pred =  0\n",
      "MSE = 13094.5\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13092.4 . Pred =  0\n",
      "MSE = 13092.4\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13090.3 . Pred =  0\n",
      "MSE = 13090.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13088.3 . Pred =  0\n",
      "MSE = 13088.3\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13086.2 . Pred =  0\n",
      "MSE = 13086.2\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13084.1 . Pred =  0\n",
      "MSE = 13084.1\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13082.0 . Pred =  0\n",
      "MSE = 13082.0\n",
      "\n",
      "Learning rate =  Tensor(\"ExponentialDecay_32:0\", shape=(), dtype=float32) . Loss =  13080.0 . Pred =  0\n",
      "MSE = 13080.0\n",
      "\n",
      "Best theta:\n",
      "[[ 27.0093174 ]\n",
      " [  5.13608265]\n",
      " [ 47.52104568]]\n",
      "Epochs :  499\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "epoch = 0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    losses = [];\n",
    "    pred_loss = 0;\n",
    "    \n",
    "    # Loop until it converges\n",
    "    # while True:\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X_data: X_train_bias, y_data: y_train})\n",
    "        \n",
    "        loss = sess.run(mse, feed_dict={X_data: X_train_bias, y_data: y_train})\n",
    "        losses.append(loss)\n",
    "#         epoch = epoch + 1\n",
    "        \n",
    "        print(\"Learning rate = \", learning_rate, \". Loss = \", loss, \". Pred = \", pred_loss)\n",
    "        print(\"MSE =\", loss)\n",
    "        print()\n",
    "        \n",
    "#         if np.abs(pred_loss - loss) < 0.001 :\n",
    "#             break\n",
    "#         else: \n",
    "#             pred_loss = loss;\n",
    "        # learning_rate = learning_rate_decay(learning_rate, epoch)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)\n",
    "print(\"Epochs : \", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEACAYAAABhzAtFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkDEzs2wcMmZmlo1DxszMsnHImJlZNv8feLI0AV5T3QkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19681b13c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the losses\n",
    "\n",
    "plt.plot(range(n_epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
